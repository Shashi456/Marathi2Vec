{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marathi2Vec Language Modeling\n",
    "\n",
    "Thanks to NirantK and cstorm125 for the works Hindi2Vec and Thai2Vec, both of which helped me make this notebook. \n",
    "\n",
    "The goal of this notebook is to train Marathi word embeddings using the fast.ai version of AWD LSTM with dropouts, the data was fulled from Wikipedia.\n",
    "\n",
    "A perplexity of was achieved, there has been no comparable research work in Marathi Language at the point of writing. (2nd October, 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import dill as pickle\n",
    "import json \n",
    "import re\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab\n",
    "from torchtext import data as d\n",
    "from torchtext.datasets import language_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data  LICENSE  Marathi2Vec.ipynb  README.md\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!cd Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Download or clone WikiExtractor from github\n",
    " - To run on windows look at [this](https://github.com/attardi/wikiextractor/issues/89#issuecomment-272062219).\n",
    " \n",
    " Run the following command :\n",
    " \n",
    " ```python WikiExtractor.py mrwiki-latest-pages-articles.xml -o extract -b 10M --ignored_tags abbr,b,big --discard_elements gallery,timeline,noinclude```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Data/'\n",
    "extract= f'{data}extract/'\n",
    "train_set = f'{data}train/'\n",
    "valid_set = f'{data}valid/'\n",
    "models = f'{data}models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CPU times: user 3.48 s, sys: 164 ms, total: 3.64 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%prun\n",
    "\n",
    "\n",
    "\n",
    "ext =  !ls {extract}\n",
    "\n",
    "def cleanFile(extracted_filelist, dest):    \n",
    "    cleaned_all = []\n",
    "    for ext_file in extracted_filelist:\n",
    "        input_file = f'{extract}{ext_file}'\n",
    "        with open(input_file,'r', encoding='utf-8') as f:\n",
    "            raw_txt = f.readlines()\n",
    "            cleaned_doc = []\n",
    "            for line in raw_txt:\n",
    "                new_line = re.sub('<[^<]+?>', '', line)\n",
    "                new_line = re.sub('__[^<]+?__', '', new_line) \n",
    "                new_line = new_line.strip()\n",
    "                if new_line != '':\n",
    "                    cleaned_doc.append(new_line)\n",
    "\n",
    "            new_doc = \"\\n\".join(cleaned_doc)\n",
    "            cleaned_all.append(new_doc)\n",
    "            with open(f\"{dest}{ext_file}.txt\", \"w\", encoding='utf-8') as text_file:\n",
    "                text_file.write(new_doc)\n",
    "    return cleaned_all\n",
    "\n",
    "cleaned_all = cleanFile(ext, train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wiki_00.txt', 'wiki_06.txt']\n",
      "['wiki_09.txt', 'wiki_07.txt', 'wiki_03.txt', 'wiki_02.txt', 'wiki_08.txt', 'wiki_05.txt', 'wiki_04.txt', 'wiki_01.txt']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(782)\n",
    "\n",
    "training_files = !ls {train_set}\n",
    "validation_files = !ls {valid_set} \n",
    "split = int(0.2 * len(training_files)) #Doing a 80-20 split\n",
    "random.shuffle(training_files)\n",
    "validation_files = training_files[:split]\n",
    "training_files = training_files[split:]\n",
    "\n",
    "print(validation_files)\n",
    "print(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wiki_01.txt', 'wiki_02.txt', 'wiki_03.txt', 'wiki_04.txt', 'wiki_05.txt', 'wiki_07.txt', 'wiki_08.txt', 'wiki_09.txt']\n",
      "['wiki_00.txt', 'wiki_06.txt']\n",
      "8\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil, os\n",
    "for root, dirs, files in os.walk(train_set):\n",
    "     for file in files:\n",
    "         if file.endswith(\".txt\") & (file in validation_files):\n",
    "             shutil.move(os.path.join(root, file),valid_set)\n",
    "trn_files = !ls {train_set}\n",
    "val_files = !ls {valid_set}\n",
    "print(trn_files), print(val_files), print(len(trn_files)), print(len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "There aren't any known Marathi Stemmers available in Python, So i've written these porting taking inspiration from Spacy's hindi tokenizer and stemmer, Since Marathi and Hindi Inherently come from the same script i.e Devanagri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " from cltk.tokenize.sentence import TokenizeSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(document):\n",
    "    tokenizer = TokenizeSentence('marathi')\n",
    "    return tokenizer.tokenize(document)\n",
    "    \n",
    "def docs_tokenize(documents_as_lists):   \n",
    "    for document in documents_as_lists:\n",
    "        tokens = word_tokenize(document)\n",
    "        tokens_list.extend(tokens)\n",
    "    \n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from tokens_list.txt\n",
      "Found 6307733 tokens\n",
      "CPU times: user 4.4 s, sys: 268 ms, total: 4.67 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens_filename = \"tokens_list.txt\"\n",
    "tokens_list = []\n",
    "\n",
    "#TODO refactor from try except blocks to if else with if statement checking if file exists using Pathlib\n",
    "\n",
    "try:\n",
    "    print(f'Reading from {tokens_filename}')\n",
    "    with open(tokens_filename, \"r\") as f:\n",
    "         tokens_list = json.load(f)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f'FileNotFound. Trying to tokenize from cleaned_all')\n",
    "    tokens_list = docs_tokenize(cleaned_all)\n",
    "    \n",
    "    with open('tokens_list.txt', 'w') as outfile:\n",
    "        json.dump(tokens_list, outfile)\n",
    "\n",
    "print(f'Found {len(tokens_list)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "#assert torch.backends.cudnn .cudnn.is_available()\n",
    "#print(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\n",
    "#print(torch.backends.cudnn.version())\n",
    "#print(torch.backends.cudnn.version())\n",
    "#assert torch.backends.cudnn.enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = d.Field(lower=True, tokenize=word_tokenize)\n",
    "#batch size\n",
    "bs=16\n",
    "#backprop through time\n",
    "bptt=70\n",
    "test_set = f'{data}test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=f'{train_set}', validation=f'{valid_set}', test=f'{test_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 s, sys: 1.17 s, total: 31.2 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "md = LanguageModelData.from_text_files('', TEXT, **FILES, bs=bs, bptt=bptt, min_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 447 ms, sys: 19.6 ms, total: 467 ms\n",
      "Wall time: 466 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle.dump(TEXT, open(f'{data}//models//TEXT_min_freq50.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 10883, 1, 6379809)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '.', ',', 'आहे', '-', ')', 'या', 'आणि', '(', 'व', 'हे']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2449"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['आ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पायरट्स',\n",
       " 'ऑफ',\n",
       " 'द',\n",
       " 'कॅरिबियन',\n",
       " '-',\n",
       " 'अॅट',\n",
       " 'वर्ल्ड्स',\n",
       " 'एंड',\n",
       " '(',\n",
       " 'चित्रपट',\n",
       " ')',\n",
       " 'पायरट्स']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    2,  ...,   21,    0, 1141],\n",
       "         [ 182,  739,  315,  ..., 5105,   41, 6403],\n",
       "         [ 265,    0, 4817,  ...,  217, 8074,   11],\n",
       "         ...,\n",
       "         [ 118,    0, 3121,  ...,  173,   11,    4],\n",
       "         [   2,   61,   18,  ..., 4224,  383,    2],\n",
       "         [1354,    0,    2,  ...,   21,    0, 5834]], device='cuda:0'),\n",
       " tensor([ 182,  739,  315,  ...,  378,   60, 4220], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [ 182],\n",
       "        [ 265],\n",
       "        [4577],\n",
       "        [   5],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   9],\n",
       "        [ 107]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trn_ds is list; one for each txt file\n",
    "txt = md.trn_ds[0].text[:10]\n",
    "TEXT.numericalize([txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5733d8c734624d38bb99a5696f8329ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 4390/5695 [19:32<05:48,  3.75it/s, loss=19]  "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find suitable learning rates\n",
    "learner.lr_find(1e-07,1e2)\n",
    "\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59960b0e429545fd9d11f9afa3e1ac37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      5.477827   5.596106  \n",
      " 73%|███████▎  | 4160/5695 [18:54<06:58,  3.67it/s, loss=4.87]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      5.045255   5.181519                                \n",
      " 14%|█▍        | 795/5695 [03:36<22:17,  3.66it/s, loss=5.07]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3141/5695 [14:16<11:36,  3.67it/s, loss=4.94]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5389/5695 [24:34<01:23,  3.66it/s, loss=4.92]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1837/5695 [08:06<17:02,  3.77it/s, loss=4.89]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4175/5695 [18:24<06:42,  3.78it/s, loss=4.47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3      4.70627    4.850859                                \n",
      "    4      4.589127   4.694453                                \n",
      " 58%|█████▊    | 3323/5695 [15:01<10:43,  3.69it/s, loss=4.51]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 5420/5695 [24:28<01:14,  3.69it/s, loss=4.45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2055/5695 [09:06<16:07,  3.76it/s, loss=4.6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4161/5695 [18:23<06:46,  3.77it/s, loss=4.2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6      4.457709   4.598827                                \n",
      " 11%|█▏        | 652/5695 [02:52<22:12,  3.78it/s, loss=4.53]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7      4.386027   4.5027                                  \n",
      "    8      4.263231   4.391432                                \n",
      "    9      4.193189   4.313699                                \n",
      "    10     4.176238   4.256015                                \n",
      "    11     4.174038   4.217817                                \n",
      "100%|█████████▉| 5671/5695 [25:02<00:06,  3.77it/s, loss=4.06]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2128/5695 [09:38<16:09,  3.68it/s, loss=4.15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 4370/5695 [19:46<05:59,  3.68it/s, loss=4.12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14     4.13349    4.179739                                \n"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n",
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('mar_adam_enc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f29dc7a79c4c14ae511ee7cd59bc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.11519    4.177755  \n",
      "    1      3.874369   4.019278                                \n",
      "    2      3.746939   3.849714                                \n",
      " 63%|██████▎   | 3582/5695 [16:20<09:38,  3.65it/s, loss=3.77]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3      3.669387   3.745317                                \n",
      "  3%|▎         | 171/5695 [00:48<26:18,  3.50it/s, loss=3.82]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2284/5695 [10:53<16:16,  3.49it/s, loss=3.84]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 4475/5695 [21:24<05:50,  3.48it/s, loss=3.81]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4      3.615256   3.674289                                \n",
      " 18%|█▊        | 1009/5695 [04:27<20:43,  3.77it/s, loss=3.44]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3348/5695 [14:49<10:23,  3.76it/s, loss=3.63]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 5554/5695 [24:32<00:37,  3.77it/s, loss=3.5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2060/5695 [09:17<16:24,  3.69it/s, loss=3.68]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 4285/5695 [19:20<06:21,  3.69it/s, loss=3.53]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6      3.596615   3.584729                                \n",
      " 15%|█▍        | 851/5695 [03:50<21:53,  3.69it/s, loss=3.62]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3035/5695 [13:40<11:58,  3.70it/s, loss=3.62]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 5178/5695 [23:20<02:19,  3.70it/s, loss=3.55]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1737/5695 [07:51<17:54,  3.68it/s, loss=3.51]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3757/5695 [17:00<08:46,  3.68it/s, loss=3.3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8      3.488636   3.509863                                \n",
      "  3%|▎         | 198/5695 [00:51<23:50,  3.84it/s, loss=3.66]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9      3.486521   3.483568                                \n",
      "    10     3.508965   3.459164                                \n",
      "    11     3.425149   3.422537                                \n",
      " 72%|███████▏  | 4086/5695 [18:10<07:09,  3.75it/s, loss=3.37]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 5685/5695 [25:14<00:02,  3.75it/s, loss=3.47]    12     3.555664   3.41939   \n",
      " 10%|▉         | 564/5695 [02:34<23:24,  3.65it/s, loss=3.55]"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef2776d49f94df8a645022a969f2854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      3.547923   3.511553  \n",
      "    1      3.446109   3.449121                                \n",
      "    2      3.436924   3.388949                                \n",
      "    3      3.338178   3.331549                                \n",
      "    4      3.37434    3.309025                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.30903])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-3, 1, wds=1e-6, cycle_len=5, cycle_save_name='adam3_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('mar_adam3_20')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=\"\"\"सुनीतिने पुत्र ध्रुवाला म्हणाली की श्रीविष्णूची उपासना कर,तो जगतपालक पिता आहे. परमात्मा श्रीविष्णूनारायणच्या मांडीवर बसायचे असेल तर बस. नन्तर तो ध्रुव पाच वयापासून राजवाड्या सोडून गेला,अशा प्रकारे बालक ध्रुव यमुना नदीच्या किनारावर पोहचला मग तो यमुना नदीत स्नान करत होता त्या मर्गात देवऋषि नारद भेटतो.देवऋषि नारदांनी ध्रुवाला सांगितले की घरी परत जावे, परंतु ध्रुवाला विश्वास नव्हता, तर नारदांनी ध्रुवाला ओम् नमो भगवते वासुदेवाय या मंत्राची दीक्षा दिली .देवऋषि नारद तिथून निघून गेला. आणि तपश्चर्येची सुरुवात झाली. एका पायावर उभे राहून सहा महिने कठोर तपस्या  केले. ॐ नमो भगवते वासुदेवाय मन्त्र ध्वनि वैकुंठ पर्यत पोहचले.\"\"\"\n",
    "s = [word_tokenize(ss)]\n",
    "t = TEXT.numericalize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "     0\n",
       "   672\n",
       "     0\n",
       "     0\n",
       "    91\n",
       "     0\n",
       "  4316\n",
       "  1506\n",
       "     3\n",
       "    63\n",
       "     0\n",
       "  4454\n",
       "     4\n",
       "     2\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "   406\n",
       "    37\n",
       "   758\n",
       "     2\n",
       "     0\n",
       "  7715\n",
       "   345\n",
       "     0\n",
       "     0\n",
       "   861\n",
       "   242\n",
       "     3\n",
       "    88\n",
       "   815\n",
       "  7726\n",
       "  7715\n",
       "  5261\n",
       "   533\n",
       "     0\n",
       "     0\n",
       "   610\n",
       "    63\n",
       "  5261\n",
       "  5869\n",
       "  4125\n",
       "   249\n",
       "    28\n",
       "    42\n",
       "     0\n",
       "     0\n",
       " 10263\n",
       "     0\n",
       "     2\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "   518\n",
       "    91\n",
       "  1164\n",
       "   505\n",
       "  1564\n",
       "     3\n",
       "   155\n",
       "     0\n",
       "  1435\n",
       "  1538\n",
       "     3\n",
       "    37\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     7\n",
       "     0\n",
       "  3962\n",
       "     0\n",
       "     2\n",
       "     0\n",
       " 10263\n",
       "  4452\n",
       "  2765\n",
       "   242\n",
       "     2\n",
       "     8\n",
       "     0\n",
       "   281\n",
       "    66\n",
       "     2\n",
       "    84\n",
       "     0\n",
       "  1031\n",
       "  1727\n",
       "   546\n",
       "  1462\n",
       "  4483\n",
       "     0\n",
       "    26\n",
       "     2\n",
       "  8357\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     2\n",
       "[torch.cuda.LongTensor of size 107x1 (GPU 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res, *other_things = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "    3.8011e-02 -2.2014e-02  7.8308e-02  ...  -1.6953e-02  4.8350e-02 -4.5729e-03\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    3.0540e-02  2.4192e-01 -6.9744e-03  ...  -6.5229e-01 -2.2948e-01  4.1202e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    1.7917e-01  2.3620e-01  3.5599e-01  ...  -6.2822e-03  4.9435e-02 -7.2944e-04\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "    1.1183e-01 -1.7880e-02  1.7792e-01  ...  -8.4721e-03  1.7791e-02 -3.8099e-03\n",
       "  \n",
       "  (105,.,.) = \n",
       "    1.1294e-01 -1.5163e-02  1.9261e-01  ...  -1.4744e-03  1.7169e-02 -3.7645e-03\n",
       "  \n",
       "  (106,.,.) = \n",
       "    3.7854e-03  4.2614e-03  1.8565e-01  ...  -4.1853e-03  1.8322e-03 -6.5098e-03\n",
       "  [torch.cuda.FloatTensor of size 107x1x500 (GPU 0)], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -1.3693e-02  1.2531e-02 -2.9094e-03  ...   8.3595e-02 -9.4321e-03  4.7299e-02\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    5.8883e-02 -8.9473e-02 -2.0179e-02  ...   1.7967e-02 -6.9051e-02 -6.5057e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    2.5043e-01 -3.5599e-02  4.0335e-02  ...   6.7441e-02 -2.5366e-02  3.1976e-01\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "    1.3150e-01  1.6566e-02  1.1248e-02  ...   1.4673e-01  8.8040e-03  9.0558e-02\n",
       "  \n",
       "  (105,.,.) = \n",
       "    1.0114e-01  1.3189e-02  1.4481e-02  ...   1.5172e-01  4.9296e-04  8.1459e-02\n",
       "  \n",
       "  (106,.,.) = \n",
       "    5.0000e-02 -7.1263e-03  1.1574e-01  ...  -1.4631e-01 -1.0540e-01  8.2688e-03\n",
       "  [torch.cuda.FloatTensor of size 107x1x500 (GPU 0)], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -2.5287e-01  1.4962e-01 -4.1486e-02  ...  -1.2742e-01  5.7312e-04  1.2624e-01\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "   -3.9699e-01  5.3612e-03 -5.8304e-02  ...  -1.0350e-01  7.1244e-02  2.3644e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "   -6.6691e-01  3.2507e-02 -1.1971e-01  ...   1.7572e-01 -3.7840e-02  9.0600e-02\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "   -1.2590e-01 -3.9704e-02 -3.1279e-01  ...   5.4518e-02 -1.1388e-01  1.9546e-01\n",
       "  \n",
       "  (105,.,.) = \n",
       "   -1.1294e-01 -4.0921e-02 -3.1317e-01  ...   6.3882e-02 -1.2052e-01  1.9467e-01\n",
       "  \n",
       "  (106,.,.) = \n",
       "   -4.1523e-01  1.0555e-01  6.2137e-02  ...   2.7275e-01 -1.3135e-01 -4.9468e-02\n",
       "  [torch.cuda.FloatTensor of size 107x1x300 (GPU 0)]], [Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "    3.8011e-02 -2.2014e-02  7.8308e-02  ...  -1.6953e-02  4.8350e-02 -4.5729e-03\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    3.0540e-02  2.4192e-01 -6.9744e-03  ...  -6.5229e-01 -2.2948e-01  4.1202e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    1.7917e-01  2.3620e-01  3.5599e-01  ...  -6.2822e-03  4.9435e-02 -7.2944e-04\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "    1.1183e-01 -1.7880e-02  1.7792e-01  ...  -8.4721e-03  1.7791e-02 -3.8099e-03\n",
       "  \n",
       "  (105,.,.) = \n",
       "    1.1294e-01 -1.5163e-02  1.9261e-01  ...  -1.4744e-03  1.7169e-02 -3.7645e-03\n",
       "  \n",
       "  (106,.,.) = \n",
       "    3.7854e-03  4.2614e-03  1.8565e-01  ...  -4.1853e-03  1.8322e-03 -6.5098e-03\n",
       "  [torch.cuda.FloatTensor of size 107x1x500 (GPU 0)], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -1.3693e-02  1.2531e-02 -2.9094e-03  ...   8.3595e-02 -9.4321e-03  4.7299e-02\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "    5.8883e-02 -8.9473e-02 -2.0179e-02  ...   1.7967e-02 -6.9051e-02 -6.5057e-02\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "    2.5043e-01 -3.5599e-02  4.0335e-02  ...   6.7441e-02 -2.5366e-02  3.1976e-01\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "    1.3150e-01  1.6566e-02  1.1248e-02  ...   1.4673e-01  8.8040e-03  9.0558e-02\n",
       "  \n",
       "  (105,.,.) = \n",
       "    1.0114e-01  1.3189e-02  1.4481e-02  ...   1.5172e-01  4.9296e-04  8.1459e-02\n",
       "  \n",
       "  (106,.,.) = \n",
       "    5.0000e-02 -7.1263e-03  1.1574e-01  ...  -1.4631e-01 -1.0540e-01  8.2688e-03\n",
       "  [torch.cuda.FloatTensor of size 107x1x500 (GPU 0)], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -2.5287e-01  1.4962e-01 -4.1486e-02  ...  -1.2742e-01  5.7312e-04  1.2624e-01\n",
       "  \n",
       "  ( 1 ,.,.) = \n",
       "   -3.9699e-01  5.3612e-03 -5.8304e-02  ...  -1.0350e-01  7.1244e-02  2.3644e-01\n",
       "  \n",
       "  ( 2 ,.,.) = \n",
       "   -6.6691e-01  3.2507e-02 -1.1971e-01  ...   1.7572e-01 -3.7840e-02  9.0600e-02\n",
       "  ... \n",
       "  \n",
       "  (104,.,.) = \n",
       "   -1.2590e-01 -3.9704e-02 -3.1279e-01  ...   5.4518e-02 -1.1388e-01  1.9546e-01\n",
       "  \n",
       "  (105,.,.) = \n",
       "   -1.1294e-01 -4.0921e-02 -3.1317e-01  ...   6.3882e-02 -1.2052e-01  1.9467e-01\n",
       "  \n",
       "  (106,.,.) = \n",
       "   -4.1523e-01  1.0555e-01  6.2137e-02  ...   2.7275e-01 -1.3135e-01 -4.9468e-02\n",
       "  [torch.cuda.FloatTensor of size 107x1x300 (GPU 0)]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "other_things\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'त्या', 'या', 'तेव्हा', 'पण', 'तो', 'आणि', 'परंतु', '.', 'ते']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "सुनीतिने पुत्र ध्रुवाला म्हणाली की श्रीविष्णूची उपासना कर,तो जगतपालक पिता आहे. परमात्मा श्रीविष्णूनारायणच्या मांडीवर बसायचे असेल तर बस. नन्तर तो ध्रुव पाच वयापासून राजवाड्या सोडून गेला,अशा प्रकारे बालक ध्रुव यमुना नदीच्या किनारावर पोहचला मग तो यमुना नदीत स्नान करत होता त्या मर्गात देवऋषि नारद भेटतो.देवऋषि नारदांनी ध्रुवाला सांगितले की घरी परत जावे, परंतु ध्रुवाला विश्वास नव्हता, तर नारदांनी ध्रुवाला ओम् नमो भगवते वासुदेवाय या मंत्राची दीक्षा दिली .देवऋषि नारद तिथून निघून गेला. आणि तपश्चर्येची सुरुवात झाली. एका पायावर उभे राहून सहा महिने कठोर तपस्या  केले. ॐ नमो भगवते वासुदेवाय मन्त्र ध्वनि वैकुंठ पर्यत पोहचले. \n",
      "\n",
      "त्या वेळी त्या त्या वेळी त्या त्या वेळी त्या त्या वेळी त्या त्या वेळी त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या त्या त्या त्या ठिकाणी त्या त्या त्या त्या त्या त्या ...\n"
     ]
    }
   ],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(100):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/models/wiki_lang.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-35d0bdea7f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TEXT = pickle.load(open(f'{data}models/TEXT.pkl','rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data}models/wiki_lang.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/models/wiki_lang.pkl'"
     ]
    }
   ],
   "source": [
    "#TEXT = pickle.load(open(f'{data}models/TEXT.pkl','rb'))\n",
    "m = pickle.load(open(f'{data}models/wiki_lang.pkl','rb'))\n",
    "m[0].bs=1\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model\n",
    "pickle.dump(m,open(f'{data}models/wiki_lang.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(ss,topk):\n",
    "    s = [word_tokenize(ss)]\n",
    "    t = TEXT.numericalize(s)\n",
    "    m.reset()\n",
    "    pred,*_ = m(t)\n",
    "    pred_i = torch.topk(pred[-1], topk)[1]\n",
    "    return [TEXT.vocab.itos[o] for o in to_np(pred_i)]\n",
    "\n",
    "\n",
    "def gen_sentences(ss,nb_words):\n",
    "    result = []\n",
    "    s = [word_tokenize(ss)]\n",
    "    t = TEXT.numericalize(s)\n",
    "    m.reset()\n",
    "    pred,*_ = m(t)\n",
    "    for i in range(nb_words):\n",
    "        pred_i = pred[-1].topk(2)[1]\n",
    "        pred_i = pred_i[1] if pred_i.data[0] < 2 else pred_i[0]\n",
    "        result.append(TEXT.vocab.itos[pred_i.data[0]])\n",
    "        pred,*_ = m(pred_i[0].unsqueeze(0))\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', ',', '(', '.', '-', 'आणि', 'व', 'या', 'हे', 'एक']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = 'मांडीवरुन'\n",
    "gen_text(ss,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',आणिइतरअनेकठिकाणी,तसेच,काहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी,आणिकाहीठिकाणी'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(gen_sentences(ss,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = list(learner.model.named_parameters())[0][1]\n",
    "emb_np = to_np(emb_weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10883, 300)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{data}//models//TEXT_min_freq50.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.set_vectors(vectors=emb_weights.data,dim=300,stoi=TEXT.vocab.stoi)\n",
    "pickle.dump(TEXT, open(f'{data}models/TEXT_vec.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_vec = pickle.load(open(f'{data}models/TEXT_vec.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "      <td>0.184997</td>\n",
       "      <td>0.264473</td>\n",
       "      <td>-0.097014</td>\n",
       "      <td>-0.290698</td>\n",
       "      <td>1.087013</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>-0.130357</td>\n",
       "      <td>-0.075503</td>\n",
       "      <td>-1.033792</td>\n",
       "      <td>-0.094126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188687</td>\n",
       "      <td>0.614073</td>\n",
       "      <td>0.030553</td>\n",
       "      <td>0.120845</td>\n",
       "      <td>-0.069144</td>\n",
       "      <td>0.575417</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>-0.102559</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.096940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;pad&gt;</th>\n",
       "      <td>1.111438</td>\n",
       "      <td>-0.647768</td>\n",
       "      <td>-0.130779</td>\n",
       "      <td>0.539828</td>\n",
       "      <td>-0.731522</td>\n",
       "      <td>-0.184220</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.267929</td>\n",
       "      <td>0.771284</td>\n",
       "      <td>0.171368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130344</td>\n",
       "      <td>-0.858178</td>\n",
       "      <td>0.127670</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>-0.486750</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.369913</td>\n",
       "      <td>0.223407</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>-0.127747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.507393</td>\n",
       "      <td>-0.548240</td>\n",
       "      <td>-0.233227</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.163352</td>\n",
       "      <td>-0.169116</td>\n",
       "      <td>0.243545</td>\n",
       "      <td>0.058599</td>\n",
       "      <td>-0.830403</td>\n",
       "      <td>0.296732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331643</td>\n",
       "      <td>0.385975</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>-0.071620</td>\n",
       "      <td>-0.131696</td>\n",
       "      <td>0.533716</td>\n",
       "      <td>-0.107223</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>-0.314744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.144995</td>\n",
       "      <td>0.153567</td>\n",
       "      <td>0.023297</td>\n",
       "      <td>1.201630</td>\n",
       "      <td>0.204971</td>\n",
       "      <td>-0.058352</td>\n",
       "      <td>0.322609</td>\n",
       "      <td>-0.045884</td>\n",
       "      <td>-0.394390</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421565</td>\n",
       "      <td>0.524912</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>-0.061385</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.326663</td>\n",
       "      <td>0.297671</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>-0.226861</td>\n",
       "      <td>-0.054824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आहे</th>\n",
       "      <td>0.735788</td>\n",
       "      <td>-0.691541</td>\n",
       "      <td>-0.172692</td>\n",
       "      <td>0.698590</td>\n",
       "      <td>0.261332</td>\n",
       "      <td>-0.262978</td>\n",
       "      <td>0.329193</td>\n",
       "      <td>0.069133</td>\n",
       "      <td>-0.301735</td>\n",
       "      <td>0.042741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292696</td>\n",
       "      <td>0.116984</td>\n",
       "      <td>-0.042562</td>\n",
       "      <td>0.255620</td>\n",
       "      <td>-0.374256</td>\n",
       "      <td>-0.051591</td>\n",
       "      <td>0.584917</td>\n",
       "      <td>-0.022902</td>\n",
       "      <td>0.311255</td>\n",
       "      <td>0.051013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.195843</td>\n",
       "      <td>0.212652</td>\n",
       "      <td>-0.080147</td>\n",
       "      <td>0.244377</td>\n",
       "      <td>-0.114356</td>\n",
       "      <td>-0.089846</td>\n",
       "      <td>0.242360</td>\n",
       "      <td>-0.397300</td>\n",
       "      <td>0.961301</td>\n",
       "      <td>-0.160332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255346</td>\n",
       "      <td>0.282573</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>-0.017026</td>\n",
       "      <td>-0.274331</td>\n",
       "      <td>-1.616143</td>\n",
       "      <td>0.260197</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>-0.302228</td>\n",
       "      <td>-0.440643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>1.403893</td>\n",
       "      <td>-0.514077</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>1.457787</td>\n",
       "      <td>-0.698837</td>\n",
       "      <td>-0.402772</td>\n",
       "      <td>-0.254091</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>1.874941</td>\n",
       "      <td>-0.323439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586915</td>\n",
       "      <td>0.284783</td>\n",
       "      <td>0.187276</td>\n",
       "      <td>-0.093994</td>\n",
       "      <td>-0.470145</td>\n",
       "      <td>-0.256428</td>\n",
       "      <td>1.117356</td>\n",
       "      <td>0.164209</td>\n",
       "      <td>-0.183921</td>\n",
       "      <td>-0.245569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>या</th>\n",
       "      <td>-0.060040</td>\n",
       "      <td>-0.128077</td>\n",
       "      <td>-0.017541</td>\n",
       "      <td>-0.108856</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>-0.484692</td>\n",
       "      <td>0.241262</td>\n",
       "      <td>-0.030532</td>\n",
       "      <td>0.610970</td>\n",
       "      <td>0.146330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106549</td>\n",
       "      <td>-0.188705</td>\n",
       "      <td>0.215217</td>\n",
       "      <td>-0.236082</td>\n",
       "      <td>-0.635500</td>\n",
       "      <td>-0.439362</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.099556</td>\n",
       "      <td>0.223018</td>\n",
       "      <td>-0.067861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आणि</th>\n",
       "      <td>0.368652</td>\n",
       "      <td>-0.100921</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.901033</td>\n",
       "      <td>0.224826</td>\n",
       "      <td>-0.142603</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.163967</td>\n",
       "      <td>0.219325</td>\n",
       "      <td>-0.077335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066042</td>\n",
       "      <td>0.303783</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>-0.121099</td>\n",
       "      <td>-0.698943</td>\n",
       "      <td>0.222724</td>\n",
       "      <td>-0.023987</td>\n",
       "      <td>-0.195869</td>\n",
       "      <td>-0.152897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.346725</td>\n",
       "      <td>0.304007</td>\n",
       "      <td>-0.141699</td>\n",
       "      <td>1.099876</td>\n",
       "      <td>-0.483198</td>\n",
       "      <td>0.322204</td>\n",
       "      <td>-0.076687</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>-0.738378</td>\n",
       "      <td>0.036106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173015</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.168522</td>\n",
       "      <td>-0.056741</td>\n",
       "      <td>-0.155863</td>\n",
       "      <td>-0.338089</td>\n",
       "      <td>-0.244678</td>\n",
       "      <td>-0.123678</td>\n",
       "      <td>0.191682</td>\n",
       "      <td>-0.708546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "<unk>  0.184997  0.264473 -0.097014 -0.290698  1.087013 -0.012152 -0.130357   \n",
       "<pad>  1.111438 -0.647768 -0.130779  0.539828 -0.731522 -0.184220  0.017115   \n",
       ".      0.507393 -0.548240 -0.233227  0.365200  0.163352 -0.169116  0.243545   \n",
       ",      0.144995  0.153567  0.023297  1.201630  0.204971 -0.058352  0.322609   \n",
       "आहे    0.735788 -0.691541 -0.172692  0.698590  0.261332 -0.262978  0.329193   \n",
       "-      0.195843  0.212652 -0.080147  0.244377 -0.114356 -0.089846  0.242360   \n",
       ")      1.403893 -0.514077  0.012261  1.457787 -0.698837 -0.402772 -0.254091   \n",
       "या    -0.060040 -0.128077 -0.017541 -0.108856  0.048029 -0.484692  0.241262   \n",
       "आणि    0.368652 -0.100921  0.012451  0.901033  0.224826 -0.142603 -0.001697   \n",
       "(      0.346725  0.304007 -0.141699  1.099876 -0.483198  0.322204 -0.076687   \n",
       "\n",
       "            7         8         9      ...          290       291       292  \\\n",
       "<unk> -0.075503 -1.033792 -0.094126    ...    -0.188687  0.614073  0.030553   \n",
       "<pad> -0.267929  0.771284  0.171368    ...    -0.130344 -0.858178  0.127670   \n",
       ".      0.058599 -0.830403  0.296732    ...     0.331643  0.385975  0.191352   \n",
       ",     -0.045884 -0.394390  0.102550    ...     0.421565  0.524912  0.004927   \n",
       "आहे    0.069133 -0.301735  0.042741    ...    -0.292696  0.116984 -0.042562   \n",
       "-     -0.397300  0.961301 -0.160332    ...    -0.255346  0.282573  0.034157   \n",
       ")      0.013123  1.874941 -0.323439    ...     0.586915  0.284783  0.187276   \n",
       "या    -0.030532  0.610970  0.146330    ...    -0.106549 -0.188705  0.215217   \n",
       "आणि   -0.163967  0.219325 -0.077335    ...    -0.066042  0.303783  0.004747   \n",
       "(      0.007891 -0.738378  0.036106    ...    -0.173015  0.010330  0.168522   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "<unk>  0.120845 -0.069144  0.575417  0.073500 -0.102559 -0.020888  0.096940  \n",
       "<pad>  0.048101 -0.486750 -0.391033  0.369913  0.223407  0.014221 -0.127747  \n",
       ".      0.014524 -0.071620 -0.131696  0.533716 -0.107223  0.304124 -0.314744  \n",
       ",     -0.061385  0.005321  0.326663  0.297671  0.025799 -0.226861 -0.054824  \n",
       "आहे    0.255620 -0.374256 -0.051591  0.584917 -0.022902  0.311255  0.051013  \n",
       "-     -0.017026 -0.274331 -1.616143  0.260197  0.043800 -0.302228 -0.440643  \n",
       ")     -0.093994 -0.470145 -0.256428  1.117356  0.164209 -0.183921 -0.245569  \n",
       "या    -0.236082 -0.635500 -0.439362 -0.045556 -0.099556  0.223018 -0.067861  \n",
       "आणि   -0.056713 -0.121099 -0.698943  0.222724 -0.023987 -0.195869 -0.152897  \n",
       "(     -0.056741 -0.155863 -0.338089 -0.244678 -0.123678  0.191682 -0.708546  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Marathi2Vec = pd.DataFrame(to_np(TEXT_vec.vocab.vectors))\n",
    "Marathi2Vec.index = TEXT_vec.vocab.itos\n",
    "Marathi2Vec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10883, 300)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Marathi2save = Marathi2Vec[~hindi2vec.index.str.contains(' ')]\n",
    "\n",
    "Marathi2save.to_csv(f'{data}models//Marathi2Vec.vec',sep=' ',header=False, line_terminator='\\n')\n",
    "#add NB_ROWS NB_COLS as header\n",
    "Marathi2save.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
