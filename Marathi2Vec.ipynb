{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marathi2Vec Language Modeling\n",
    "\n",
    "Thanks to NirantK and cstorm125 for the works Hindi2Vec and Thai2Vec, both of which helped me make this notebook. \n",
    "\n",
    "The goal of this notebook is to train Marathi word embeddings using the fast.ai version of AWD LSTM with dropouts, the data was fulled from Wikipedia.\n",
    "\n",
    "A perplexity of was achieved, there has been no comparable research work in Marathi Language at the point of writing. (2nd October, 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import dill as pickle\n",
    "import json \n",
    "import re\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab\n",
    "from torchtext import data as d\n",
    "from torchtext.datasets import language_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data  LICENSE  Marathi2Vec.ipynb  README.md\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!cd Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Download or clone WikiExtractor from github\n",
    " - To run on windows look at [this](https://github.com/attardi/wikiextractor/issues/89#issuecomment-272062219).\n",
    " \n",
    " Run the following command :\n",
    " \n",
    " ```python WikiExtractor.py mrwiki-latest-pages-articles.xml -o extract -b 10M --ignored_tags abbr,b,big --discard_elements gallery,timeline,noinclude```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Data/'\n",
    "extract= f'{data}extract/'\n",
    "train_set = f'{data}train/'\n",
    "valid_set = f'{data}valid/'\n",
    "models = f'{data}models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CPU times: user 3.48 s, sys: 164 ms, total: 3.64 s\n",
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%prun\n",
    "\n",
    "\n",
    "\n",
    "ext =  !ls {extract}\n",
    "\n",
    "def cleanFile(extracted_filelist, dest):    \n",
    "    cleaned_all = []\n",
    "    for ext_file in extracted_filelist:\n",
    "        input_file = f'{extract}{ext_file}'\n",
    "        with open(input_file,'r', encoding='utf-8') as f:\n",
    "            raw_txt = f.readlines()\n",
    "            cleaned_doc = []\n",
    "            for line in raw_txt:\n",
    "                new_line = re.sub('<[^<]+?>', '', line)\n",
    "                new_line = re.sub('__[^<]+?__', '', new_line) \n",
    "                new_line = new_line.strip()\n",
    "                if new_line != '':\n",
    "                    cleaned_doc.append(new_line)\n",
    "\n",
    "            new_doc = \"\\n\".join(cleaned_doc)\n",
    "            cleaned_all.append(new_doc)\n",
    "            with open(f\"{dest}{ext_file}.txt\", \"w\", encoding='utf-8') as text_file:\n",
    "                text_file.write(new_doc)\n",
    "    return cleaned_all\n",
    "\n",
    "cleaned_all = cleanFile(ext, train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wiki_00.txt', 'wiki_06.txt']\n",
      "['wiki_09.txt', 'wiki_07.txt', 'wiki_03.txt', 'wiki_02.txt', 'wiki_08.txt', 'wiki_05.txt', 'wiki_04.txt', 'wiki_01.txt']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(782)\n",
    "\n",
    "training_files = !ls {train_set}\n",
    "validation_files = !ls {valid_set} \n",
    "split = int(0.2 * len(training_files)) #Doing a 80-20 split\n",
    "random.shuffle(training_files)\n",
    "validation_files = training_files[:split]\n",
    "training_files = training_files[split:]\n",
    "\n",
    "print(validation_files)\n",
    "print(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wiki_01.txt', 'wiki_02.txt', 'wiki_03.txt', 'wiki_04.txt', 'wiki_05.txt', 'wiki_07.txt', 'wiki_08.txt', 'wiki_09.txt']\n",
      "['wiki_00.txt', 'wiki_06.txt']\n",
      "8\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil, os\n",
    "for root, dirs, files in os.walk(train_set):\n",
    "     for file in files:\n",
    "         if file.endswith(\".txt\") & (file in validation_files):\n",
    "             shutil.move(os.path.join(root, file),valid_set)\n",
    "trn_files = !ls {train_set}\n",
    "val_files = !ls {valid_set}\n",
    "print(trn_files), print(val_files), print(len(trn_files)), print(len(val_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "There aren't any known Marathi Stemmers available in Python, So i've written these porting taking inspiration from Spacy's hindi tokenizer and stemmer, Since Marathi and Hindi Inherently come from the same script i.e Devanagri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " from cltk.tokenize.sentence import TokenizeSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(document):\n",
    "    tokenizer = TokenizeSentence('marathi')\n",
    "    return tokenizer.tokenize(document)\n",
    "    \n",
    "def docs_tokenize(documents_as_lists):   \n",
    "    for document in documents_as_lists:\n",
    "        tokens = word_tokenize(document)\n",
    "        tokens_list.extend(tokens)\n",
    "    \n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from tokens_list.txt\n",
      "Found 6307733 tokens\n",
      "CPU times: user 4.4 s, sys: 268 ms, total: 4.67 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens_filename = \"tokens_list.txt\"\n",
    "tokens_list = []\n",
    "\n",
    "#TODO refactor from try except blocks to if else with if statement checking if file exists using Pathlib\n",
    "\n",
    "try:\n",
    "    print(f'Reading from {tokens_filename}')\n",
    "    with open(tokens_filename, \"r\") as f:\n",
    "         tokens_list = json.load(f)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f'FileNotFound. Trying to tokenize from cleaned_all')\n",
    "    tokens_list = docs_tokenize(cleaned_all)\n",
    "    \n",
    "    with open('tokens_list.txt', 'w') as outfile:\n",
    "        json.dump(tokens_list, outfile)\n",
    "\n",
    "print(f'Found {len(tokens_list)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert torch.cuda.is_available()\n",
    "#assert torch.backends.cudnn .cudnn.is_available()\n",
    "#print(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\n",
    "#print(torch.backends.cudnn.version())\n",
    "#print(torch.backends.cudnn.version())\n",
    "#assert torch.backends.cudnn.enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = d.Field(lower=True, tokenize=word_tokenize)\n",
    "#batch size\n",
    "bs=16\n",
    "#backprop through time\n",
    "bptt=70\n",
    "test_set = f'{data}test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=f'{train_set}', validation=f'{valid_set}', test=f'{test_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 s, sys: 1.99 s, total: 34.4 s\n",
      "Wall time: 37.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "md = LanguageModelData.from_text_files('', TEXT, **FILES, bs=bs, bptt=bptt, min_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 447 ms, sys: 19.6 ms, total: 467 ms\n",
      "Wall time: 466 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pickle.dump(TEXT, open(f'{data}//models//TEXT_min_freq50.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 10883, 1, 6379809)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '.', ',', 'आहे', '-', ')', 'या', 'आणि', '(', 'व', 'हे']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2449"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['आ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पायरट्स',\n",
       " 'ऑफ',\n",
       " 'द',\n",
       " 'कॅरिबियन',\n",
       " '-',\n",
       " 'अॅट',\n",
       " 'वर्ल्ड्स',\n",
       " 'एंड',\n",
       " '(',\n",
       " 'चित्रपट',\n",
       " ')',\n",
       " 'पायरट्स']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,    2,  ...,   21,    0, 1141],\n",
       "         [ 182,  739,  315,  ..., 5105,   41, 6403],\n",
       "         [ 265,    0, 4817,  ...,  217, 8074,   11],\n",
       "         ...,\n",
       "         [ 118,    0, 3121,  ...,  173,   11,    4],\n",
       "         [   2,   61,   18,  ..., 4224,  383,    2],\n",
       "         [1354,    0,    2,  ...,   21,    0, 5834]], device='cuda:0'),\n",
       " tensor([ 182,  739,  315,  ...,  378,   60, 4220], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [ 182],\n",
       "        [ 265],\n",
       "        [4577],\n",
       "        [   5],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   0],\n",
       "        [   9],\n",
       "        [ 107]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trn_ds is list; one for each txt file\n",
    "txt = md.trn_ds[0].text[:10]\n",
    "TEXT.numericalize([txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 300  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5733d8c734624d38bb99a5696f8329ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 4390/5695 [19:32<05:48,  3.75it/s, loss=19]  "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find suitable learning rates\n",
    "learner.lr_find(1e-07,1e2)\n",
    "\n",
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59960b0e429545fd9d11f9afa3e1ac37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      5.477827   5.596106  \n",
      " 73%|███████▎  | 4160/5695 [18:54<06:58,  3.67it/s, loss=4.87]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      5.045255   5.181519                                \n",
      " 14%|█▍        | 795/5695 [03:36<22:17,  3.66it/s, loss=5.07]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3141/5695 [14:16<11:36,  3.67it/s, loss=4.94]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5389/5695 [24:34<01:23,  3.66it/s, loss=4.92]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1837/5695 [08:06<17:02,  3.77it/s, loss=4.89]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4175/5695 [18:24<06:42,  3.78it/s, loss=4.47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3      4.70627    4.850859                                \n",
      "    4      4.589127   4.694453                                \n",
      " 58%|█████▊    | 3323/5695 [15:01<10:43,  3.69it/s, loss=4.51]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 5420/5695 [24:28<01:14,  3.69it/s, loss=4.45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2055/5695 [09:06<16:07,  3.76it/s, loss=4.6] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 4161/5695 [18:23<06:46,  3.77it/s, loss=4.2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6      4.457709   4.598827                                \n",
      " 11%|█▏        | 652/5695 [02:52<22:12,  3.78it/s, loss=4.53]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1602/5695 [07:03<18:03,  3.78it/s, loss=4.31]"
     ]
    }
   ],
   "source": [
    "learner.fit(1e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n",
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
