{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marathi2Vec Language Modeling\n",
    "\n",
    "Thanks to NirantK and cstorm125 for the works Hindi2Vec and Thai2Vec, both of which helped me make this notebook. \n",
    "\n",
    "The goal of this notebook is to train Marathi word embeddings using the fast.ai version of AWD LSTM with dropouts, the data was fulled from Wikipedia.\n",
    "\n",
    "A perplexity of was achieved, there has been no comparable research work in Marathi Language at the point of writing. (2nd October, 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import dill as pickle\n",
    "import json \n",
    "import re\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Download or clone WikiExtractor from github\n",
    " - To run on windows look at [this](https://github.com/attardi/wikiextractor/issues/89#issuecomment-272062219).\n",
    " \n",
    " Run the following command :\n",
    " \n",
    " ```python WikiExtractor.py mrwiki-latest-pages-articles.xml -o extract -b 10M --ignored_tags abbr,b,big --discard_elements gallery,timeline,noinclude```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%prun\n",
    "\n",
    "data = '../extract/'\n",
    "extracted_files = f'{data}'\n",
    "\n",
    "def clean_files(extracted_filelist, TRN):    \n",
    "    cleaned_all = []\n",
    "    for ext_file in extracted_filelist:\n",
    "        input_file = f'{EXT}{ext_file}'\n",
    "        with open(input_file,'r', encoding='utf-8') as f:\n",
    "            raw_txt = f.readlines()\n",
    "            cleaned_doc = []\n",
    "            for line in raw_txt:\n",
    "                new_line = re.sub('<[^<]+?>', '', line)\n",
    "                new_line = re.sub('__[^<]+?__', '', new_line) \n",
    "                new_line = new_line.strip()\n",
    "                if new_line != '':\n",
    "                    cleaned_doc.append(new_line)\n",
    "\n",
    "            new_doc = \"\\n\".join(cleaned_doc)\n",
    "            cleaned_all.append(new_doc)\n",
    "            with open(f\"{TRN}{ext_file}.txt\", \"w\", encoding='utf-8') as text_file:\n",
    "                text_file.write(new_doc)\n",
    "    return cleaned_all\n",
    "\n",
    "cleaned_all = clean_files(ext_files, TRN)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
